---
title: 'LLMs: CS324'
date: 2025-03-14
permalink: /posts/2025/03/cs324/
tags:
  - Deep Learning
  - 
  - 
---

# CS324

[TOC]

## 1. Introduction
### 1.  language model
1. 概述 \
   LM 的经典定义是：token sequence 的概率分布，概率表示了序列的好坏程度。例如，对于一个词典：V = {ate, ball, cheese, mouse, the}，LM 可能分配的概率：
   - p(𝗍𝗁𝖾,𝗆𝗈𝗎𝗌𝖾,𝖺𝗍𝖾,𝗍𝗁𝖾,𝖼𝗁𝖾𝖾𝗌𝖾)=0.02,
   - p(𝗍𝗁𝖾,𝖼𝗁𝖾𝖾𝗌𝖾,𝖺𝗍𝖾,𝗍𝗁𝖾,𝗆𝗈𝗎𝗌𝖾)=0.01,
   - p(𝗆𝗈𝗎𝗌𝖾,𝗍𝗁𝖾,𝗍𝗁𝖾,𝖼𝗁𝖾𝖾𝗌𝖾,𝖺𝗍𝖾)=0.0001.
   这种概率分配需要很强的 linguistic 和 world knowledge。

2. Autoregressive language models \
   对于 token seq 通常用概率的链式法则描述其联合分布，其实就是条件概率。\
   p(𝗍𝗁𝖾,𝗆𝗈𝗎𝗌𝖾,𝖺𝗍𝖾,𝗍𝗁𝖾,𝖼𝗁𝖾𝖾𝗌𝖾)=
   p(𝗍𝗁𝖾)
   p(𝗆𝗈𝗎𝗌𝖾∣𝗍𝗁𝖾)
   p(𝖺𝗍𝖾∣𝗍𝗁𝖾,𝗆𝗈𝗎𝗌𝖾)
   p(𝗍𝗁𝖾∣𝗍𝗁𝖾,𝗆𝗈𝗎𝗌𝖾,𝖺𝗍𝖾)
   p(𝖼𝗁𝖾𝖾𝗌𝖾∣𝗍𝗁𝖾,𝗆𝗈𝗎𝗌𝖾,𝖺𝗍𝖾,𝗍𝗁𝖾) \
   第 i 个位置的 token 是前 i-1 个 token 的条件概率。

3. temperature：
   通过温度参数调整模型输出的概率分布，控制生成文本的随机性。
   - 最终 logits = 原始 logits / Temperature
   - 高温（T > 1）：概率分布趋于平缓，低概率词被提升，结果更随机、多样性。但可能降低连贯性，适用于创意写作。
   - 低温（T < 1）：概率分布趋于尖锐，高概率词更突出，生成结果更确定、保守。可能重复或单调，适用于高准确性任务，代码生成。
   - 极端情况：T = 0:退化为贪心搜索，始终选择最高概率。T = ∞，所有词概率均等，从均匀分布取样完全随机。
   - 通常与 top-k，top-p 采样结合，进一步控制。
   - 代码生成：T = 0.0
   - 对话系统：T = 1.3
   - 故事创作：T = 1.5
   - T 不参与训练，仅影响推理的采样过程。

4. Language modeling：
   - 核心也就是 next word prediction，根据前面的token序列预测下一个token的概率，目标是让计算机学会理解和生成人类语言。loss = -log(p(条件概率))
   - 概率建模：通过分析大量文本数据，学习词语之间的关联规律，计算某个词在特定上下文中出现的概率，即 $$ P(w_t | w_1, w_2, ..., w_{t-1}) $$ 根据前文预测下一个词的概率。
   - 评价指标：困惑度（Perplexity）衡量模型对测试数据的预测能力，越低越好。

5. Generation \
   从自回归 LM 的概率分布中每次 smaple 一个 token。通过超参 T：temperature 控制随机程度 variability。

6. Conditional generation \
   指定 prefix sequence，也即 prompt，从 LM 中采样剩下的部分，也叫 completion。\
   通过改变 prompt 控制 completion

### history
1. Information theory \
   信息熵用来量化信息中的随机性，本质上衡量了一个概率分布的混乱程度：熵值越高，不确定性越大，能携带的信息量也越多。\
   - 一句话：位数的平均值
   - 概率越小的事件，发生时提供的信息量越大。（熵高）
   - 例如抛硬币，如果正反面概率各 50%，则熵值最大，不确定性最高。如果每次都是正面，p(x)=1，熵为 0，没有不确定性。
   distribution entropy: 
   $$ H(p)=∑_xp(x)log\frac{1}{p(x)} $$
   - 事件发生的概率 * 所需位数
   - 信息量：平均需要多少比特的信息来描述一个事件。例如，熵为 1 bit，表示平均需要 1 位二进制数来编码。
   对于 seq of tokens 来说，LM 的概率分布 p 的熵值衡量了：对于从概率分布 p 中 sample 得到的 x，把它编码（压缩）成 bitstring 需要的平均位数。

2. Cross Entropy \
   交叉熵用于衡量两个概率分布之间的差异，核心是评估预测分布相对于真实分布的不匹配程度。
   - 真实分布 p(x)
   - 预测分布 q(x)
   $$ H(p,q)=∑_xp(x)log\frac{1}{q(x)} $$
   这里 1/q(x) 表示编码后的长度。交叉熵越小，说明预测分布越接近真实分布。
   - KL 散度（相对熵） = 交叉熵 - 信息熵
   - 作为分类任务的损失函数：真实分布是gt的标签y，通常用 one-hot 向量形式表示，例如[0,1,0]，即y=1，因此交叉熵被简化为 -log(预测概率p)。
   - 和 MSE（均方误差）的区别：分类问题中，概率接近0或1时，交叉熵避免梯度消失。MSE对概率的惩罚不敏感，易导致训练缓慢。

### KL 散度和交叉熵的区别：
- 一句话：分类模型用交叉熵损失，衡量两个分布的差异用 KL 散度。当真实分布 P 是确定性分布（如 One-Hot 标签）时，信息熵 H(P) = 0，此时交叉熵 = KL 散度。
1. 交叉熵：衡量用分布 Q 描述真实分布 P 所需的平均编码长度。绝对代价，直接量化用 Q 编码 P 的信息效率。
2. KL 散度：衡量分布 P 与 Q 之间的差异（信息损失）。相对差异，量化 P 相对于 Q 的额外信息量。
3. 交叉熵 = 真实分布 P 的信息熵 + KL 散度（当 Q 完全匹配 P 时，KL 散度=0，此时交叉熵等于信息熵）
4. 应用差异：
   - 监督学习分类任务：交叉熵直接作为损失函数
   - 概率模型评估：KL 散度衡量生成模型（GAN, VAE）的输出分布与真实分布的差异。（不直接用交叉熵衡量分布差异）

### 为什么分类任务用交叉熵作为损失函数
1. 核心思想：
   - 分类模型的本质是学习一个概率分布 Q（模型预测），使其逼近真实分布 P（标签的 One-Hot 编码）
2. 最大似然估计：最小化交叉熵损失等价于最大化样本的似然函数
   - 例如：真实标签 y = [0, 0, 1]，模型预测概率 [0.1, 0.2, 0.7]
   - 似然函数：L = 最大化正确类别的概率 P(y_3 = 1)
   - 取负对数 -logL = -logP(y_3=1)，与交叉熵形式一致。

## 2. Capability
